# Project Status and Next Steps

## Current Implementation Status

### âœ… Completed Features

#### 1. Core Schema Processing
- **Schema Fetcher**: Downloads Swagger/OpenAPI schemas from URLs
- **Schema Processor**: Processes and extracts schema information
- **Schema Analyzer**: Analyzes schemas for test traceability with complexity metrics

#### 2. LLM Integration
- **LLM Prompter**: Generates Gherkin test scenarios using OpenAI GPT-4
- **Smart Chunking**: Handles large schemas by processing in chunks
- **Token Management**: Automatic token limit handling

#### 3. BRD (Business Requirement Document) System
- **BRD Schema**: Complete schema definition for BRD documents
- **BRD Loader**: Loads/saves BRD schemas from JSON files
- **BRD Parser**: Parses BRD documents from various formats (PDF, Word, TXT, CSV, etc.) using LLM
- **BRD Generator**: Generates BRD schemas from Swagger using LLM with heuristic analysis
- **Schema Cross-Reference**: Cross-references BRD with Swagger to filter test scope

#### 4. Analytics and Reporting
- **Metrics Collector**: Tracks LLM API execution metrics
- **Algorithm Tracking**: Detailed algorithm-specific analysis and complexity metrics
- **Report Generation**: Separate reports for each algorithm/LLM call
- **Complexity Analysis**: Input/output complexity, structure analysis, execution time

#### 5. Output Generation
- **CSV Generator**: Converts Gherkin scenarios to CSV format
- **Analytics Reports**: Comprehensive analytics in `output/analytics/`
- **Algorithm Reports**: Detailed reports in `output/analytics/reports/`

### ğŸ“ Project Structure

```
api-param-coverage/
â”œâ”€â”€ src/modules/
â”‚   â”œâ”€â”€ swagger_tool/          # Schema downloading and validation
â”‚   â”œâ”€â”€ engine/                # Processing and LLM generation
â”‚   â”‚   â”œâ”€â”€ algorithms/        # Schema processing algorithms
â”‚   â”‚   â”œâ”€â”€ analytics/         # Analytics and reporting
â”‚   â”‚   â””â”€â”€ llm/              # LLM prompting
â”‚   â”œâ”€â”€ brd/                   # Business Requirement Document
â”‚   â”‚   â”œâ”€â”€ brd_schema.py
â”‚   â”‚   â”œâ”€â”€ brd_loader.py
â”‚   â”‚   â”œâ”€â”€ brd_parser.py
â”‚   â”‚   â””â”€â”€ schema_cross_reference.py
â”‚   â””â”€â”€ brd_generator/        # BRD generation
â”‚       â””â”€â”€ brd_generator.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ schemas/              # Downloaded schemas
â”œâ”€â”€ reference/                # Reference data
â”‚   â””â”€â”€ brd/
â”‚       â””â”€â”€ input/            # BRD schema files
â”‚           â””â”€â”€ README.md     # BRD schema format documentation
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ *.csv                 # Generated CSV files
â”‚   â””â”€â”€ analytics/
â”‚       â”œâ”€â”€ *.txt             # LLM execution metrics
â”‚       â””â”€â”€ reports/          # Algorithm-specific reports
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ latex/                # LaTeX monography files
â”‚   â””â”€â”€ PROJECT_STATUS.md     # This file
â””â”€â”€ main.py                   # Main entry point
```

### ğŸ”„ Current Workflow

1. **Schema Download**: User provides Swagger/OpenAPI schema URL
2. **Schema Processing**: Process and analyze schema
3. **BRD Handling**: 
   - Option 1: Load existing BRD file
   - Option 2: Generate BRD from Swagger using LLM
   - Option 3: Parse BRD from document (PDF, Word, TXT, CSV)
4. **Cross-Reference**: Filter endpoints by BRD requirements
5. **Test Generation**: Generate Gherkin scenarios only for BRD-covered endpoints
6. **CSV Export**: Save test scenarios to CSV
7. **Analytics**: Track all algorithm executions and LLM calls

## ğŸ¯ Next Steps / Future Enhancements

### High Priority

1. **LaTeX Parser Integration**
   - Parse LaTeX files from `docs/latex/` folder
   - Extract content for monography/report generation
   - Integrate with BRD system for documentation

2. **Enhanced BRD Parser**
   - Improve document format support (better PDF/Word parsing)
   - Add validation for parsed BRD schemas
   - Support for more document formats (Excel, Markdown)

3. **Algorithm Performance Optimization**
   - Analyze algorithm reports for bottlenecks
   - Optimize complexity calculations
   - Improve execution time tracking

### Medium Priority

4. **Test Coverage Analysis**
   - Generate coverage reports comparing BRD requirements vs generated tests
   - Visualize coverage gaps
   - Suggest missing test scenarios

5. **BRD Validation**
   - Validate BRD schemas against Swagger endpoints
   - Check for missing endpoints in BRD
   - Suggest BRD improvements

6. **Advanced Analytics**
   - Aggregate analytics across multiple runs
   - Trend analysis for algorithm performance
   - Cost tracking for LLM API calls

### Low Priority

7. **UI/CLI Improvements**
   - Interactive mode for BRD selection
   - Progress bars for long operations
   - Better error messages and recovery

8. **Configuration Management**
   - Config file for default settings
   - Environment-specific configurations
   - Customizable algorithm parameters

9. **Export Formats**
   - Export to other test management formats (JIRA, TestRail, etc.)
   - JSON export for programmatic use
   - HTML reports with visualizations

## ğŸ“ Notes

### Current Dependencies
- OpenAI API key required for LLM features
- Optional: PyPDF2 for PDF parsing
- Optional: python-docx for Word document parsing

### Known Limitations
- Large schemas may require chunking (handled automatically)
- BRD parsing quality depends on document structure
- Token limits may affect very large prompts (handled with warnings)

### Testing Status
- Core algorithms have test coverage
- LLM integration tests may require API key
- BRD parser tests need sample documents

## ğŸ”§ Maintenance Tasks

1. **Code Quality**
   - Review and refactor complex algorithms
   - Improve error handling
   - Add more comprehensive tests

2. **Documentation**
   - Update README with new features
   - Add API documentation
   - Create user guide

3. **Performance**
   - Profile algorithm execution
   - Optimize data structures
   - Cache frequently used computations

## ğŸ“Š Analytics Insights

The analytics system tracks:
- **LLM Calls**: Token usage, execution time, prompt/response sizes
- **Algorithm Performance**: Execution time, input/output complexity
- **Complexity Metrics**: Endpoints, parameters, requirements analysis
- **Coverage Metrics**: BRD coverage percentage, filtered endpoints

All reports are saved in `output/analytics/reports/` for analysis.

